{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaded in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full 30min dataset for streaming video on vpn\n",
    "yes = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102.csv\")\n",
    "# full 30min dataset for web browsing on vpn\n",
    "no = pd.read_csv(\"apristin-novideo-vpn-windows-20201109.csv\")\n",
    "\n",
    "# 5 minute chunks of streaming video on vpn\n",
    "yes_0 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-0.csv\")\n",
    "yes_1 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-1.csv\")\n",
    "yes_2 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-2.csv\")\n",
    "yes_3 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-3.csv\")\n",
    "yes_4 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-4.csv\")\n",
    "yes_5 = pd.read_csv(\"apristin-youtube[1440p60]-1x-vpn-windows-noisy-20201102-5.csv\")\n",
    "# 5 minute chuncks of web browsing on vpn\n",
    "no_0 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-0.csv\")\n",
    "no_1 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-1.csv\")\n",
    "no_2 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-2.csv\")\n",
    "no_3 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-3.csv\")\n",
    "no_4 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-4.csv\")\n",
    "no_5 = pd.read_csv(\"apristin-novideo-vpn-windows-20201109-5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that I have the function below that cleans the extended columns and creates individual dataframes for each row's extended columns in the original dataset, I can further examine the data and engineer new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns a dataframe with the packets times, sizes, and directions for a single row of data\n",
    "def three_cols(row):\n",
    "    time = list(map(int, row['packet_times'].split(';')[0:-1]))\n",
    "    size = list(map(int, row['packet_sizes'].split(';')[0:-1]))\n",
    "    dirs = list(map(int, row['packet_dirs'].split(';')[0:-1]))\n",
    "    dict1 = {'packet_time': time, 'packet_size': size, 'packet_dir': dirs}\n",
    "    return pd.DataFrame(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packet Size Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the majority of packet sizes range from 0-300 bytes and 1200-1500 bytes, I think that developing a feature on the counts of those ranges can be beneficial in discovering if streaming is occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes all the counts of the 0-300bytes for the 1->2 Direction and all the counts\n",
    "# of the 1200-1500bytes for the 2->1 Direction and creates new columns based off this in the dataframe\n",
    "def big_byte_count_feature(dataset):        \n",
    "    df = dataset.copy()\n",
    "    packet_size_count1 = []\n",
    "    packet_size_count2 = []\n",
    "    for i in range(df.shape[0]):\n",
    "        row = three_cols(df.iloc[i])\n",
    "        ones = row.loc[row['packet_dir'] == 1]['packet_size']\n",
    "        twos = row.loc[row['packet_dir'] == 2]['packet_size']\n",
    "        one_count=0\n",
    "        two_count=0\n",
    "        for packet in ones:\n",
    "            if (int(packet) >= 0) and (int(packet) <= 300):\n",
    "                one_count += 1\n",
    "        for packet in twos:\n",
    "            if (int(packet) >= 1200) and (int(packet) <= 1500):\n",
    "                two_count += 1\n",
    "        packet_size_count1.append(one_count)\n",
    "        packet_size_count2.append(two_count)\n",
    "    return df.assign(Dir1_ByteCount_0to300 = packet_size_count1, Dir2_ByteCount_1200to1500 = packet_size_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The way that I would use the two features I created above in my machine learning model would be by looking at the counts of the byte ranges and training my model on this since there is a clear divide between the range count of streaming vs non-streaming, as the count of the ranges are significantly higher when streaming is occuring. This is evident in my examples below for no streaming vs streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dir1_ByteCount_0to300  Dir2_ByteCount_1200to1500\n",
      "0                   1288                       2232\n",
      "1                    709                       1402\n",
      "2                   1646                       3124\n",
      "3                    585                        876\n",
      "4                      2                          0\n",
      "No Streaming Byte Count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dir1_ByteCount_0to300        31958\n",
       "Dir2_ByteCount_1200to1500    68755\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of byte count feature extraction on the no streaming dataset:\n",
    "big_byte_no_streaming = big_byte_count_feature(yes_0)\n",
    "print(big_byte_no_streaming[['Dir1_ByteCount_0to300', 'Dir2_ByteCount_1200to1500']].head(5))\n",
    "print(\"No Streaming Byte Count:\")\n",
    "big_byte_no_streaming[['Dir1_ByteCount_0to300', 'Dir2_ByteCount_1200to1500']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Dir1_ByteCount_0to300  Dir2_ByteCount_1200to1500\n",
      "0                   1288                       2232\n",
      "1                    709                       1402\n",
      "2                   1646                       3124\n",
      "3                    585                        876\n",
      "4                      2                          0\n",
      "Streaming Byte Count:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dir1_ByteCount_0to300        194108\n",
       "Dir2_ByteCount_1200to1500    430519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of byte count feature extraction on the streaming dataset:\n",
    "big_byte_streaming = big_byte_count_feature(yes)\n",
    "print(big_byte_streaming[['Dir1_ByteCount_0to300', 'Dir2_ByteCount_1200to1500']].head(5))\n",
    "print(\"Streaming Byte Count:\")\n",
    "big_byte_streaming[['Dir1_ByteCount_0to300', 'Dir2_ByteCount_1200to1500']].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
